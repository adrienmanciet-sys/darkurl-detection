{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54f09a18",
   "metadata": {},
   "source": [
    "---\n",
    "# URL Reputation\n",
    "### Adrien Manciet - Thibault Sourdeval\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc2125",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Ce dataset est un ensemble d'url qui sont labellisés. Si le label vaut 1, l'url est dangereux, si il vaut -1, il ne l'est pas. L'objectif sera de faire un algorithme de classification des url en apprenant sur le dataset disponible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ba05ad",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 1 - Phase d'exploration\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4fcf97",
   "metadata": {},
   "source": [
    "Nous notons que les fichiers de données sont sous la forme de matrices sparse. Cela signifie que seules les valeurs non nulles sont gardées en mémoire. \n",
    "Cela permet d'épargner des erreurs de mémoire. \n",
    "\n",
    "Le fichier features contient des numéros qui semblent correspondre à des subdivisions de l'url contenant en blocs. Exemple : la première ligne du fichier features affiche 4, ce qui pourrait correspondre aux quatres premiers caractères de l'url 'http'. \n",
    "\n",
    "Nous codons une fonction de prévisualisation pour mieux comprendre la structure des données en les transformant en un dataframe. Pour la suite, \n",
    "nous resterons dans le format de données initial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86f1b2",
   "metadata": {},
   "source": [
    "**Chargement des modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d658b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_svmlight_file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa199ea",
   "metadata": {},
   "source": [
    "**Fonction de prévisualisation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20bb0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_data(day, nb_lines, nb_cols, random = True):\n",
    "    # Si random est laissé tel quel, une valeur au hasard \n",
    "    # est prise pour la première ligne et la première colonne à afficher\n",
    "\n",
    "    path =f\"url_svmlight/url_svmlight/Day{day}.svm\"\n",
    "    X, y = load_svmlight_file(path)\n",
    "    print(\"Les données sont de taille : \", X.shape)\n",
    "\n",
    "    if random == True:\n",
    "        start_line = np.random.randint(0, len(y)-nb_lines)\n",
    "        start_col = np.random.randint(0,X.shape[1])\n",
    "    else : \n",
    "        start_line = int(input(\"Première ligne à afficher : \"))\n",
    "        start_col = int(input(\"Première colonne à afficher : \"))\n",
    "    \n",
    "    label_list = []\n",
    "    for i in range(start_col, start_col+nb_cols):\n",
    "        label_list.append(i)\n",
    "\n",
    "    X_df = pd.DataFrame(X[start_line: start_line+nb_lines, start_col: start_col+nb_cols].toarray(), columns=label_list)\n",
    "    y_df = pd.DataFrame(y[start_line: start_line+nb_lines], columns=['label'])\n",
    "\n",
    "    data = pd.concat([X_df, y_df], axis=1)\n",
    "    return data\n",
    "\n",
    "preview_data(17, 10, 10, random=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c6a25",
   "metadata": {},
   "source": [
    "**Visualisations grahiques** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061f163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plot(day, feature_x, feature_y): \n",
    "    path =f\"url_svmlight/url_svmlight/Day{day}.svm\"\n",
    "    X, y = load_svmlight_file(path)\n",
    "\n",
    "    X = X[0:2000,:2000].toarray()\n",
    "    plt.figure()\n",
    "    plt.grid(alpha=0.2)\n",
    "    sc = plt.scatter(X[:,feature_x], X[:,feature_y], c=y[0:2000], cmap=\"viridis\",alpha=0.5)\n",
    "    plt.xlabel(f'Feature {feature_x}')\n",
    "    plt.ylabel(f'Feature {feature_y}')\n",
    "    \n",
    "\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "scatter_plot(11,4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a282ca7e",
   "metadata": {},
   "source": [
    "**Commentaires sur les features**\n",
    "\n",
    "Elles ne correspondent pas à des critères interprétables par l'humain. Probablement, ce sont des indicateurs de présence de certains mots, ou certains caractères dans un découpage de l'url qui est défini dans le fichier `features_types`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79f2bb",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 2 - Feature Engineering\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa2efa",
   "metadata": {},
   "source": [
    "Comme beaucoup de nos colonnes de features ne contiennent que des 0 ou des 1, et que cela ne permettra pas la classification, nous décidons d'enlever ces colonnes dans les données qui serveront à l'apprentissage. \n",
    "\n",
    "Pour ce faire, nous utilisons un critère sur la variance minimale d'une colonne dans chaque fichier. Puis, nous regardons le nombre de fichier pour lesquels une colonne a été gardée. Nous mesurons cela en pourcentage. \n",
    ">Exemple : la colonne 1 a une variance supérieure au critère minimal dans les fichiers 1 à 10, mais pas dans les fichiers 11 à 20. Ainsi, l'algorithme a gardé la colonne un pour les fichiers 1 à 10 et l'a enlevée dans les autres. Au total, la colonne 1 a été gardée dans 50% des cas.\n",
    "\n",
    "Dans un premier temps, nous gardons les colonnes dès lors qu'elles sont gardées au moins une fois, soit que leur pourcentage d'apparition est strictement positif. Nous pourrons raffiner cela pour garder moins de features si on voit que cela améliore la performance de la méthode d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f8498a",
   "metadata": {},
   "source": [
    "### Sélection des features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9271f908",
   "metadata": {},
   "source": [
    "**Trouver les features à garder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357852a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "import os\n",
    "\n",
    "data_dir = \"url_svmlight/url_svmlight\"\n",
    "max_features = 3300000  # à adapter à ton dataset\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "\n",
    "# Préparer la liste des fichiers à traiter\n",
    "files_to_process = sorted(os.listdir(data_dir))[:50]  # exemple sur 10 jours\n",
    "num_files = len(files_to_process)\n",
    "\n",
    "# Initialiser UN SEUL tableau pour compter les sélections\n",
    "# C'est beaucoup plus efficace en mémoire\n",
    "column_keep_counts = np.zeros(max_features, dtype=int)\n",
    "\n",
    "print(f\"Traitement de {num_files} fichiers...\")\n",
    "\n",
    "# Boucle sur les fichiers\n",
    "for file in files_to_process:\n",
    "    X, y = load_svmlight_file(os.path.join(data_dir, file), n_features=max_features)\n",
    "    \n",
    "    # On a seulement besoin de \"fit\", pas de \"fit_transform\" si on n'utilise pas X_reduced\n",
    "    selector.fit(X) \n",
    "    \n",
    "    keep_mask = selector.get_support()  # booléen : True si la colonne est gardée\n",
    "    \n",
    "    # --- La voici, l'optimisation ---\n",
    "    # On ajoute le masque (True=1, False=0) à notre compteur total\n",
    "    column_keep_counts += keep_mask\n",
    "    # ---------------------------------\n",
    "    print(f\"Traitement {file} terminé.\")\n",
    "\n",
    "print(\"Traitement terminé.\")\n",
    "\n",
    "# Calculer le pourcentage (exactement comme avant, mais sans la grosse matrice)\n",
    "column_keep_percentage = (column_keep_counts / num_files) * 100\n",
    "\n",
    "# Créer DataFrame en ne gardant que les colonnes qui ont été sélectionnées au moins une fois\n",
    "df_keep = pd.DataFrame({\n",
    "    'column_index': np.arange(len(column_keep_percentage)),\n",
    "    'percent_kept': column_keep_percentage\n",
    "})\n",
    "\n",
    "# Filtrer les colonnes jamais gardées\n",
    "df_keep = df_keep[df_keep['percent_kept'] > 0]\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b9114f",
   "metadata": {},
   "source": [
    "**Filtrer et concaténer toutes les données chargées en ne conservant que les features sélectionnées précédemment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import vstack, csr_matrix\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "data_dir = \"url_svmlight/url_svmlight\"\n",
    "\n",
    "X_filtered_all = None\n",
    "y_all = []\n",
    "\n",
    "# -------------------------------\n",
    "# Boucle sur les fichiers\n",
    "# -------------------------------\n",
    "for file in sorted(os.listdir(data_dir))[:30]:\n",
    "    print(f\"Traitement de {file}...\")\n",
    "    X, y = load_svmlight_file(os.path.join(data_dir, file), n_features=max_features)\n",
    "    \n",
    "    # Filtrage sur les mêmes colonnes\n",
    "    X_filtered = X[:, df_keep['column_index']]\n",
    "    \n",
    "    # Concaténation verticale\n",
    "    if X_filtered_all is None:\n",
    "        X_filtered_all = X_filtered\n",
    "    else:\n",
    "        X_filtered_all = vstack([X_filtered_all, X_filtered])\n",
    "    \n",
    "    y_all.append(y)\n",
    "\n",
    "# -------------------------------\n",
    "# Concaténer les labels\n",
    "# -------------------------------\n",
    "y_all = np.concatenate(y_all)\n",
    "\n",
    "# -------------------------------\n",
    "# Vérification finale\n",
    "# -------------------------------\n",
    "print(\"Shape finale :\", X_filtered_all.shape)\n",
    "print(\"Nombre total d'échantillons :\", X_filtered_all.shape[0])\n",
    "print(\"Nombre de colonnes (features) :\", X_filtered_all.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87cd035",
   "metadata": {},
   "source": [
    "**Séparation du jeu de données en train et test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bebbb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# Définir la taille du jeu de test (ex: 20%)\n",
    "TAILLE_TEST = 0.2\n",
    "\n",
    "# 1. Créer le split principal (Train / Test)\n",
    "# Le jeu de test (X_test, y_test) ne sera plus touché avant l'évaluation finale.\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X_filtered_all, \n",
    "    y_all, \n",
    "    test_size=TAILLE_TEST, \n",
    "    stratify=y_all,  # Garde les proportions de classes\n",
    "    random_state=42 # Pour la reproductibilité\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8606d91b",
   "metadata": {},
   "source": [
    "Nous appliquons un scaler, le `MaxAbsScaler` est plus adapté que le `StandardScaler` pour des données clairsemées (sparse), c'est-à-dire contenant beaucoup de zéros. Ceci est bien le cas de notre jeu de données, d'où l'utilisation de cette méthode de pré-traitement des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110dda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_full)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Taille dataset complet : {X_filtered_all.shape[0]} échantillons\")\n",
    "print(f\"Taille jeu d'entraînement complet : {X_train_full.shape[0]} échantillons\")\n",
    "print(f\"Taille jeu de test : {X_test.shape[0]} échantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f901ca2",
   "metadata": {},
   "source": [
    "**Option : réduction de la taille des jeux de données précédents pour entraîner des modèles de manière exploratoire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452cdc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir la fraction du jeu d'entraînement que vous voulez garder\n",
    "# Ex: 0.1 (soit 10% du X_train_full, ou 8% du dataset total)\n",
    "TAILLE_TRAIN_REDUIT = 0.1 \n",
    "\n",
    "# 2. Créer l'échantillon réduit à partir du jeu d'entraînement\n",
    "# On utilise train_size cette fois-ci.\n",
    "# Les '_' sont pour les variables que nous n'utiliserons pas (le reste des données)\n",
    "X_train_reduced, _, y_train_reduced, _ = train_test_split(\n",
    "    X_train_full, \n",
    "    y_train_full, \n",
    "    train_size=TAILLE_TRAIN_REDUIT, \n",
    "    stratify=y_train_full, # Garde les proportions de classes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTaille jeu d'entraînement réduit : {X_train_reduced.shape[0]} échantillons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8891e8",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 3 - Phase d'apprentissage\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cf3336",
   "metadata": {},
   "source": [
    "## Passage en revue des méthodes d'apprentissage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1652300",
   "metadata": {},
   "source": [
    "Nous commençons par faire un passage en revue des différentes méthodes sur notre jeu de données. Une de nos contraintes principales concerne la taille du jeu de données. Ainsi, nous commençons par évaluer le temps d'execution ainsi que les performances (précisions, variances) des différentes méthodes sur un jeu de données réduit. Nous appliquons ensuite la meilleure méthode au jeu de données entier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b222b",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aac7f6d",
   "metadata": {},
   "source": [
    "**SVM Linéaire**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd05b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm = LinearSVC(C=0.1, random_state=42)\n",
    "svm.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab2ce0b",
   "metadata": {},
   "source": [
    "Le résultat est déjà satisfaisant, ce qui peut laisser présupposer d'une structure multi-linéaire de notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774ace23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "svm.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0abbf5",
   "metadata": {},
   "source": [
    "Ici, le temps d'execution est plus long, sans d'amélioration significative de la précision et de la variance. C'est un résultat auquel on pouvait s'attendre puisque svm linéaire donnait de bons résultats, indiquant que notre jeu de données pouvait être séparé linéairement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a143a319",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a3dd9b",
   "metadata": {},
   "source": [
    "**Avec une distribution de probabilité de Bernoulli**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923e7d6",
   "metadata": {},
   "source": [
    "Nos données contiennent beaucoup de 0 et de 1, ce qui se prête bien à une modélisation par une loi de Bernoulli (pile ou face avec une certaine probabilité). Avec une loi Gaussienne, on peut avoir des valeurs entre 0 et 1 avec une plus grande probabilité, ce qui correspond moins à notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d693e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = BernoulliNB(alpha=0.1, binarize=None)  # binarize=None car tes features sont déjà binaires\n",
    "model.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a226b259",
   "metadata": {},
   "source": [
    "**Processus Gaussiens**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaae6802",
   "metadata": {},
   "source": [
    "Même pas essayé parce que trop long par les exemples de ton fichiers, en plus pas précis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e1cde7",
   "metadata": {},
   "source": [
    "### Algorithmes basés sur les arbres de décisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e7bab",
   "metadata": {},
   "source": [
    "**Arbre de décision simple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95eff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "model.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a41536",
   "metadata": {},
   "source": [
    "**AdaBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ff6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = AdaBoostClassifier(tree.DecisionTreeClassifier(criterion='entropy', max_depth=3), n_estimators=100)\n",
    "model.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69704a8a",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ed5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100)\n",
    "model.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6583845",
   "metadata": {},
   "source": [
    "**RandomForest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1888da8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "model.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c75d569",
   "metadata": {},
   "source": [
    "Plus long que les autres méthodes ensemblistes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b806ae",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf091a55",
   "metadata": {},
   "source": [
    "Nous avons obtenus de bons résultats en des temps raisonnables avec : \n",
    "- SVM linéaire : bonne précision, symétrie dans les erreurs, très rapide\n",
    "- Arbre de décision simple : bonne précision, symétrie acceptable, très rapide, mais nous savons qu'un arbre seul a une faible capacité de généralisation et une tendance à surapprendre contrairement aux SVM\n",
    "- XGBoost : bonne précision, moins symétrique, moins rapide\n",
    "- RandomForest : bonne précision, symétrie dans les erreurs, le moins rapide des trois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f43f8a",
   "metadata": {},
   "source": [
    "SVM linéaire, bien qu'étant une méthode simple, semble être la plus efficace sur notre jeu de données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fa75b4",
   "metadata": {},
   "source": [
    "## Approfondissement du SVM Linéaire "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ad760",
   "metadata": {},
   "source": [
    "Nous allons maintenant refaire tourner SVM linéaire sur un plus gros jeu de données, dans l'objectif de valider notre choix en faisant des validations croisées pour plus de robustesse concernant la performance de cet algorithme pour classifier les urls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4010fb",
   "metadata": {},
   "source": [
    "Au lieu de le faire tourner sur `X_train_reduced`, nous allons essayer de le faire tourner avec `X_train_full`, qui ne contient pour l'instant que 10 fichiers d'url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc634e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "svm = LinearSVC(random_state=42, C=0.1)\n",
    "svm.fit(X_train_full, y_train_full)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496bab74",
   "metadata": {},
   "source": [
    "Nous pouvons constater une légère amélioration des performances de l'algorithme ayant appris sur un jeu de données plus grand. \n",
    "Les premiers tuning de paramètres nous indiquent que : \n",
    "- une pénalité L1 ne converge que très lentement sans améliorer les performances, nous restons donc sur la pénalité L2 - ceci peut se comprendre par le fait qu'une pénalité L1 consiste à sélectionner les features qui permettent le plus de prédictivité de la classe, mais en mettant leur coefficient à 0, au lieu de très proche de 0 pour L2\n",
    "- le paramètre C qui permet d'ajuster le compromis entre la largeur de la marge qui sépare les classes des données, et les erreurs de classification : si on veut une marge très large, on doit accepter que certaines valeurs soient classées du mauvais côté de l'hyperplan. La précision s'améliore quelque peu en ajustant C, mais c'est surtout la vitesse de convergence qui est meilleure dans certains cas. Attention cependant à ne pas overfitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cfff0d",
   "metadata": {},
   "source": [
    "Le finetuning de C sera l'objet de la partie 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0b3d46",
   "metadata": {},
   "source": [
    "Néanmoins, nous pouvons d'ores et déjà faire une validation croisée sur notre jeu de données d'entraînement pour apprécier les capacités de généralisations de notre algorithme. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c81987",
   "metadata": {},
   "source": [
    "**Validation Croisée**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa274ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Initialisation du modèle\n",
    "svm = LinearSVC(random_state=42, C=1)\n",
    "\n",
    "# Définir une validation croisée stratifiée (préserve la proportion des classes)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Lancer la validation croisée\n",
    "scores = cross_val_score(svm, X_train_full, y_train_full, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\n--- Validation croisée ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print(f\"Scores individuels : {scores}\")\n",
    "print(f\"Moyenne de précision : {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfeefa",
   "metadata": {},
   "source": [
    "Nous constatons une bonne précision homogène sur chacun des folds, ce qui nous permet de conforter le choix du svm linéaire. Il est précis mais aussi robuste car très peu variable selon les jeux de données d'entraînement sélectionnés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4951f",
   "metadata": {},
   "source": [
    "Nous affichons maintenant la matrice de confusion qui permet de comprendre la répartitions des erreurs entre faux positifs et faux négatifs. Nous cherchons un algorithme qui fait des erreurs de façon symétrique, même si on peut débattre de cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa38a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm = LinearSVC(random_state=42, C=0.1)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Une seule passe de cross-validation\n",
    "y_pred_cv = cross_val_predict(svm, X_train_full, y_train_full, cv=cv, n_jobs=-1)\n",
    "\n",
    "# Calcul de la précision moyenne sur toutes les prédictions CV\n",
    "acc = accuracy_score(y_train_full, y_pred_cv)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_train_full, y_pred_cv)\n",
    "ConfusionMatrixDisplay(cm).plot()\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Validation croisée ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print(f\"Précision moyenne (CV) : {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b61cc5",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 4 - Tuning d'un hyperparamètre\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398868ca",
   "metadata": {},
   "source": [
    "### L'hyperparamètre $C$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da08a65f",
   "metadata": {},
   "source": [
    "**Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17445222",
   "metadata": {},
   "source": [
    "Nous souhaitons trouver l'hyperparamètre $C$ optimal pour le svm linéaire sur notre jeu de données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ab306c",
   "metadata": {},
   "source": [
    "Rappelons ce que contrôle $C$ dans l'algorithme. $C$ est un terme de pénalisation des erreurs de classifications : \n",
    "- si $C$ est petit, des erreurs de classifications sont tolérées. La marge du svm est plus large, ce qui en fait un algorithme avec une capacité de généralisation plus importante. \n",
    "- si $C$ est grand, moins d'erreurs de classifications sont tolérées car elles sont pénalisées plus sévèrement dans l'algorithme d'optimisation constitutif du svm. Donc, la marge est plus réduite. La précision est normalement plus grande, mais il y a un risque de surapprentissage plus élevé puisqu'on force l'algorithme à potentiellement fixer les hyperplans séparateurs sur des données qui pourraient être du bruit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cd82f1",
   "metadata": {},
   "source": [
    "**Tuning sur dataset restreint**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e001abed",
   "metadata": {},
   "source": [
    "Pour éviter les problèmes de mémoires, on entraîne sur le dataset réduit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d6bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Modèle de base\n",
    "svm = LinearSVC(random_state=42, max_iter=5000)\n",
    "\n",
    "# Grille de C à tester\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Validation croisée stratifiée\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearch\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "print(\"Best C:\", grid_search.best_params_['C'])\n",
    "print(\"Best CV score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6763df5d",
   "metadata": {},
   "source": [
    "Comme les tests de la partie précédente le laisser présager, $C=0.1$ est l'otpimum grossier de $C$. Essayons d'affiner cette recherche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13575de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèle de base\n",
    "svm = LinearSVC(random_state=42, max_iter=5000)\n",
    "\n",
    "# Grille de C à tester\n",
    "param_grid = {'C': [0.23, 0.24, 0.25, 0.26, 0.27, 0.28]}\n",
    "\n",
    "# Validation croisée stratifiée\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearch\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "print(\"Best C:\", grid_search.best_params_['C'])\n",
    "print(\"Best CV score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bef3927",
   "metadata": {},
   "source": [
    "Une recherche plus fine autour de $0,1$ a montré que $0,2$ est plus performant. Ainsi, nous avons affiné la recherche autour de $0,2$ pour trouver que $C=0,27$ nous donne les meilleures performances sur le jeu de données réduit. \n",
    "\n",
    "Il reste à confirmer cela en essayant sur le jeu de données complet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7f727",
   "metadata": {},
   "source": [
    "**Application au dataset complet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79144310",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "svm = LinearSVC(random_state=42, C=0.27)\n",
    "svm.fit(X_train_full, y_train_full)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1dfcc6",
   "metadata": {},
   "source": [
    "On constate que ce changement de paramètre a amélioré la précision de l'ordre de $0,01\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de1695",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Initialisation du modèle\n",
    "svm = LinearSVC(random_state=42, C=0.27)\n",
    "\n",
    "# Définir une validation croisée stratifiée (préserve la proportion des classes)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Lancer la validation croisée\n",
    "scores = cross_val_score(svm, X_train_full, y_train_full, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\n--- Validation croisée ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print(f\"Scores individuels : {scores}\")\n",
    "print(f\"Moyenne de précision : {np.mean(scores):.4f} ± {np.std(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5b85cc",
   "metadata": {},
   "source": [
    "On constate que la précision moyenne sur les folds a diminué de l'ordre de $0,01\\%$. Ceci est cohérent avec ce qu'attendu, nous avons augmenté la précision sur notre jeu de données d'entraînement, mais cela nous a coûté un peu de capacité de généralisation. Un compromis doit être fait entre biais et variance et $C=0,27$ semble être un bon choix de ce point de vu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9dded6",
   "metadata": {},
   "source": [
    "### Les autres hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b4459e",
   "metadata": {},
   "source": [
    "**Fonction de perte `loss`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86001b97",
   "metadata": {},
   "source": [
    "Elle définit l'erreur du modèle. Par défaut svm linéaire utilise `squared_hinge`. On pourrait utiliser `hinge` simple pour voir si cela améliore les performances du svm linéaire. Une loss en hinge est censée être plus robuste face aux outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00666b57",
   "metadata": {},
   "source": [
    "**Paramètre `dual`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ad5e7",
   "metadata": {},
   "source": [
    "Il vaut `True` par défaut, mais en le mettant à `False`, les performances pourraient être meilleures, car c'est particulièrement adapté pour des jeux de données un nombre de samples supérieur aux features, ce qui est notre cas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c63543",
   "metadata": {},
   "source": [
    "**Type de régularisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017cd922",
   "metadata": {},
   "source": [
    "Il est possible de choisir une régularisation l1 ou l2. Nous resterons sur l2 car cela offre une plus grande stabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9af276b",
   "metadata": {},
   "source": [
    "**Test sur la combinaison de ces nouveaux paramètres**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6ea224",
   "metadata": {},
   "source": [
    "Nous gardons le $C$ trouvé précédemment, mais nous ajoutons les nouveaux paramètres cités plus haut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8716a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "svm = LinearSVC(random_state=42, C=0.27, loss='hinge', penalty='l2')\n",
    "svm.fit(X_train_full, y_train_full)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\n--- Évaluation du modèle ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print('Précision de : ', accuracy_score(y_test, y_pred))\n",
    "print(\"\\nRésumé de classification:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nMatrice de confusion:\\n\", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c714a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Initialisation du modèle\n",
    "svm = LinearSVC(random_state=42, C=0.27, loss='hinge', penalty='l2')\n",
    "\n",
    "# Définir une validation croisée stratifiée (préserve la proportion des classes)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Lancer la validation croisée\n",
    "scores = cross_val_score(svm, X_train_full, y_train_full, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\n--- Validation croisée ---\")\n",
    "print(f\"Temps d'exécution : {end - start:.2f} s\")\n",
    "print(f\"Scores individuels : {scores}\")\n",
    "print(f\"Moyenne de précision : {np.mean(scores):.4f} ± {np.std(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cf881c",
   "metadata": {},
   "source": [
    "On constate une amélioration de la précision et de la moyenne de la précision sur les folds. Ces paramètres ont donc effectivement un peu amlioré la performance de notre algorithme. \n",
    "\n",
    "Néanmoins, nous avons un warning de convergence, je sais pas trop si c'est une bonne chose, je pense que non."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65721198",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 5 : Conclusions\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ec7cb",
   "metadata": {},
   "source": [
    "Pour conclure, dans ce notebook nous devions entrainer un modèle pour classifier les url entre sain et malsain. \n",
    "\n",
    "C'est une tâche de machine learning supervisée puisque les données sont labelisées (-1 pour malsain/+1 pour sain).\n",
    "\n",
    "Nous avons commencé par mettre en place un feature engineering pour extraire les features utiles à l'entrainement du modèle de machine learning. \n",
    "\n",
    "Puis nous avons entrainé et testé plusieurs algorithmes de ML (svm, arbres, naive bayes, Gaussian processes).\n",
    "\n",
    "Grâce à nos résultats, nous avons montré qu'un simple SVM linéaire suffit à obtenir une bonne précision (0.98). \n",
    "\n",
    "Ensuite nous avons fine tunné les hyperparamètres du SVM et notamment C. Nous avons pu améliorer notre précision de 0.001%.\n",
    "\n",
    "Enfin, pour améliorer notre travail si nous avions accès aux personnes \"métier\", nous aurions pu leur demandé comment ils ont fait pour passer d'un texte url à un vecteur représentant nos features dans la matrice svm. En effet, si nous comprenons mieux à quelles parties de l'url font référence les feature, nous pourrions mieux les filtrer lors de notre feature engineering.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
